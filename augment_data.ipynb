{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "2f2a1f23-b266-4f46-8290-70d9fcf43bf2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import Dataset\n",
    "\n",
    "train = Dataset.load_from_disk('train_mlc/dataset/train')\n",
    "test = Dataset.load_from_disk('train_mlc/dataset/test')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "27c09310-0983-4b40-9373-b7a19c8a1450",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/site-packages/torch/_utils.py:831: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()\n",
      "  return self.fget.__get__(instance, owner)()\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "\n",
    "# Function to generate embeddings for a query\n",
    "def embed_query(query):\n",
    "    inputs = tokenizer(query, return_tensors='pt', truncation=True, padding=True)\n",
    "    with torch.no_grad():\n",
    "        outputs = model(**inputs)\n",
    "    embedding = outputs.last_hidden_state.mean(dim=1).squeeze().numpy()\n",
    "    return embedding\n",
    "\n",
    "# Function to search the FAISS index and retrieve metadata\n",
    "def search_faiss(index, query_embedding, metadata, k=5):\n",
    "    query_embedding = np.array([query_embedding]).astype('float32')\n",
    "    distances, indices = index.search(query_embedding, k)\n",
    "    retrieved_metadata = [metadata[idx] for idx in indices[0]]\n",
    "    return distances, indices, retrieved_metadata\n",
    "\n",
    "\n",
    "from transformers import AutoModel, AutoTokenizer\n",
    "\n",
    "model_name = 'DeepPavlov/rubert-base-cased-sentence'  # Replace with your model\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "model = AutoModel.from_pretrained(model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a48d9e11-f008-4969-a9ce-7b95efa2cec7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import _pickle as pickle\n",
    "\n",
    "with open('telegram_bot/metadata.json', 'r') as f:\n",
    "    metadata = json.load(f)\n",
    "\n",
    "with open('telegram_bot/all_chunks.pkl', 'rb') as f:\n",
    "    all_chunks = pickle.load(f)\n",
    "\n",
    "with open('telegram_bot/all_metadata.pkl', 'rb') as f:\n",
    "    all_metadata = pickle.load(f)\n",
    "\n",
    "import faiss\n",
    "\n",
    "index = faiss.read_index('telegram_bot/faiss_index.index')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "b7b94f43-873d-40c1-aedc-e4cb1f863af6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def formatting(documents):\n",
    "    output = \"\"\n",
    "    for i, doc in enumerate(documents[0]):\n",
    "        output += f\"Документ {i}: {doc}\\n\\n\"\n",
    "    return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "84fc9a7c-7d83-4e58-88bc-c21d4c59cfeb",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100% 666/666 [00:18<00:00, 35.22it/s]\n"
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm\n",
    "\n",
    "retrieved_information = []\n",
    "\n",
    "for sample in tqdm(train):\n",
    "    query_embedding = embed_query(sample['question'])\n",
    "    k = 5\n",
    "    distances, indices, retrieved_metadata = search_faiss(index, query_embedding, all_metadata, k)\n",
    "    retrieved_information.append(formatting(np.array(all_chunks)[indices]))\n",
    "    # break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "4769c070-622a-4088-98b2-61592a864f8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "train = train.add_column('retrieved', retrieved_information)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "5c798d8a-d7ba-4035-8723-88c5bc95a77f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100% 167/167 [00:04<00:00, 37.10it/s]\n"
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm\n",
    "\n",
    "test_retrieved_information = []\n",
    "\n",
    "for sample in tqdm(test):\n",
    "    query_embedding = embed_query(sample['question'])\n",
    "    k = 5\n",
    "    distances, indices, retrieved_metadata = search_faiss(index, query_embedding, all_metadata, k)\n",
    "    test_retrieved_information.append(formatting(np.array(all_chunks)[indices]))\n",
    "    # break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "4d6e3a43-4ce3-4567-a77a-d4d98cbf9863",
   "metadata": {},
   "outputs": [],
   "source": [
    "test = test.add_column('retrieved', test_retrieved_information)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b19a009c-21f4-464e-a532-792bb24235e3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f2e0286-8d44-4119-9c77-1fa113211138",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "a9753d4e-e125-4548-a121-c2b79269fcd2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f765eb0d16a944128d1fc6bb74300bba",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Saving the dataset (0/1 shards):   0%|          | 0/666 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "train.save_to_disk('train_mlc/rag_dataset/train')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "839304a5-0426-4e37-86b6-e7a0f14c7e39",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "549cd29e0b234230ba2a8756453b422c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Saving the dataset (0/1 shards):   0%|          | 0/167 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "test.save_to_disk('train_mlc/rag_dataset/test')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66234db1-c5f6-42f7-b3d5-bc4aa3f25bfd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dec32f76-b00d-4a6e-bf7c-c652e3f2e119",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
